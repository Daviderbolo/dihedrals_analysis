{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "source": [
    "With this notebook, we will analyze ramachandran plots from GROMACS and compare them with database RP. Dihedrals are divided in four sets: alanine, glycine, proline and all the others.\n",
    "\n",
    "First of all, we have the functions that creates a dictionary in which each key is an amino acid and each value is a dataframe. The columns of this dataframe are the $\\phi$ and $\\psi$ dihedrals.\n",
    "The database files are in the 'database_csv' folder, while the GROMACS xvg file is in the 'input' folder.\n",
    "\n",
    "We considered four class: 'ALA', 'GLY', 'PRO', 'ALL' (which contains all the other amino acids). The whole notebook is based on data organised as follows:\n",
    "\n",
    "{'ALL': {'ARG':dataframe_arg, 'ASN':dataframe_asn, ...}}\n",
    "\n",
    "There are 4 different notebook, one for each class.\n",
    "\n",
    "\n",
    "NOTE: all the functions were designated for daset like\n",
    "\n",
    "{'ALL': {'ARG':dataframe_arg,\n",
    "\n",
    "             'ASN':dataframe_asn, ...},\n",
    "\n",
    "  'ALA': {'ALA':dataframe_ala},\n",
    "\n",
    "  'GLY': {'GLY':dataframe_gly},\n",
    " \n",
    "  'PRO': {'PRO':dataframe_pro}}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_database():#aminos):\n",
    "    #aminos is taken as input so that only the \"interesting\" aminoacid are considered.\n",
    "    aminos = ['ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'HIS', 'ILE', 'LEU', 'LYS', 'PHE', 'SER', 'THR', 'TRP', 'TYR', 'VAL']\n",
    "    \n",
    "    db_dict = {}\n",
    "\n",
    "    for amino in aminos:\n",
    "        path = 'database_csv/%s.csv' % amino\n",
    "        df = pd.read_csv(path)\n",
    "        df.columns = ['aa', 'phi', 'psi']\n",
    "        \n",
    "        df = df.drop('aa', axis =1)\n",
    "        df['weight'] = 1 /len(df.index) #normalized\n",
    "        db_dict[amino] = df\n",
    "    \n",
    "    return db_dict #IT'S GOOD, DON'T TOUCH\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "def read_rama(path):\n",
    "    #firstly, we read the .xvg file and make a proper pandas dataframe\n",
    "    data = open(path, 'r')\n",
    "    rama = pd.read_csv(data, sep = '\\s+')\n",
    "    rama.columns = ['phi', 'psi', 'aa']\n",
    "\n",
    "    #in rama.xvg data are organized as \\phi \\psi aa-num so we have to split the last index\n",
    "    rama[['type', 'num']] = rama['aa'].str.split('-', 1, expand=True)\n",
    "\n",
    "    #values sorted by amino acid so that computations can be faster to implement\n",
    "    rama = rama.drop(['aa', 'num'], axis = 1).sort_values('type').reset_index(drop=True)\n",
    "\n",
    "    aminos = rama['type'].unique()\n",
    "\n",
    "    rama_dict = {amino: rama[rama['type'] == amino].drop('type', axis = 1).reset_index() for amino in aminos}\n",
    "    \n",
    "    del rama_dict['ALA']\n",
    "    del rama_dict['GLY']\n",
    "    del rama_dict['PRO']\n",
    "\n",
    "    return {'ALL':rama_dict} #.sort_values(['row', 'col'])\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "def separate(dictionary):\n",
    "    \n",
    "    ala_dict = {'ALA':dictionary['ALA']}\n",
    "    gly_dict = {'GLY':dictionary['GLY']}\n",
    "    pro_dict = {'PRO':dictionary['PRO']}\n",
    "    del dictionary['ALA']\n",
    "    del dictionary['GLY']\n",
    "    del dictionary['PRO']\n",
    "\n",
    "    return {'ALL':dictionary, 'ALA':ala_dict, 'GLY':gly_dict, 'PRO':pro_dict}"
   ]
  },
  {
   "source": [
    "We have the $\\phi$ and $\\psi$ dihedrals. GROMACS defines two different potential term for each dihedral. They differ from each other for:\n",
    "- the constant $k_i\\geq 0$\n",
    "- the phase angle $\\theta_i \\in [-\\pi, \\pi]$\n",
    "- the multiplicity $m_i$, an integer $\\in [1,6]$\n",
    "\n",
    "To perform the reweighting, we will use the GROMACS potential given a dihedral $\\theta$:\n",
    "$$V_{i}(\\theta)=k_{i}(1+\\cos(m_i\\theta - \\theta_i))$$\n",
    "\n",
    "The values of constant and phase are randomly generated with the random.random() function. While, for multiplicity, we will modify only a single value at a time. The starting array of multiplicities will be the one of the previous best guess."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizer(mult):\n",
    "\n",
    "    dih = {'ALL': random_dihedral()}\n",
    "    const = {'ALL': random_constant(5)}\n",
    "    \n",
    "    for amino in mult.keys():\n",
    "        mult[amino][random.randrange(0,len(mult))] = random.randrange(1,7)\n",
    "    \n",
    "    return dih, const, mult\n",
    "\n",
    "\n",
    "def random_dihedral():\n",
    "\n",
    "    return [360 * random.random() - 180 for i in range(4)]\n",
    "\n",
    "\n",
    "def random_constant(limit):\n",
    "\n",
    "    return [limit * random.random() for i in range(4)]\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "def make_weights(rama_dict, dih, const, mult, beta):\n",
    "\n",
    "    for amino in rama_dict.keys():\n",
    "        rama = rama_dict.get(amino)\n",
    "        rama = rama.assign(weight=lambda x: weight(x.phi, x.psi, dih, const, mult, beta))\n",
    "    \n",
    "        rama['weight'] = rama['weight'] / np.sum(rama['weight'])\n",
    "        rama_dict[amino] = rama\n",
    "        #print(rama)\n",
    "        \n",
    "    return rama_dict\n",
    "\n",
    "\n",
    "\n",
    "def weight(phi, psi, dih, const, mult, beta):\n",
    "    \n",
    "    d2r = np.pi / 180\n",
    "    \n",
    "    gd_42 = (const[0] * ( 1 + np.cos(mult[0] * (psi * d2r) - (dih[0] * d2r))))\n",
    "    gd_43 = (const[1] * ( 1 + np.cos(mult[1] * (phi * d2r) - (dih[1] * d2r))))        \n",
    "    gd_44 = (const[2] * ( 1 + np.cos(mult[2] * (phi * d2r) - (dih[2] * d2r))))\n",
    "    gd_45 = (const[3] * ( 1 + np.cos(mult[3] * (psi * d2r) - (dih[3] * d2r))))\n",
    "\n",
    "    return np.exp(-1 * beta * (gd_42 + gd_43 + gd_44 + gd_45))"
   ]
  },
  {
   "source": [
    "The make_matrix function 'translate' our RP in a $180\\times180$ matrix, i.e. in a two-dimensional normalized histogram. Each entry of the matrix is the height of the relative bin. We will make a matrix from the db (only once, it is given as input) and one from the test data everytime we generate new random values.\n",
    "\n",
    "We have two ways to evaluate our reweighting.\n",
    "\n",
    "Firstly, we analyze its efficiency, i.e. how many bins are \"thrown away\". Given weight $w_i$ of the i-th bin, we define it as:\n",
    "$$E = \\frac{\\left( \\sum_{bins} w_i \\right)}{\\sum_{bins} (w_i)^2}$$\n",
    "We want this efficiency to be greater of a certain value.\n",
    "\n",
    "Then, we build the score function considering the weight of each bin in database $\\delta_i$ and from the reweight $\\gamma_i$:\n",
    "$$ S = \\sum_{amino acids} \\left[ \\frac{\\sum_{i} (\\delta_i - \\gamma_i)^2}{\\sum_{i} (\\delta_i)^2} \\right]$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(rama_dict):\n",
    "\n",
    "    mat_dict = {}\n",
    "\n",
    "    for amino in rama_dict.keys():\n",
    "        df = rama_dict.get(amino)\n",
    "        mat, x1, x2 = np.histogram2d(df['psi'], df['phi'], bins=180, weights=df['weight'], density=True)\n",
    "        mat_dict[amino] = mat\n",
    "        #print(len(mat))\n",
    "    \n",
    "    return mat_dict\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "def efficiency_analysis(rama_dict):\n",
    "    \n",
    "    perc = []\n",
    "\n",
    "    for amino in rama_dict.keys():\n",
    "        df = rama_dict.get(amino)\n",
    "        s_weight = np.power(np.sum(df['weight']), 2)\n",
    "        s2_weight = np.sum(np.power(df['weight'], 2))\n",
    "\n",
    "        perc.append(s_weight/(s2_weight*len(df.index)))\n",
    "    #print(perc)\n",
    "    return perc\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "def score_comp(db_mat, rama_dict):\n",
    "    \n",
    "    mats_rama = make_matrix(rama_dict)\n",
    "    scores = []\n",
    "\n",
    "    for amino in mats_rama.keys():\n",
    "\n",
    "        mat_db = db_mat.get(amino)\n",
    "        mat_rama = mats_rama.get(amino)\n",
    "    \n",
    "        mat_diff = np.power(mat_db - mat_rama, 2)\n",
    "        mat_sq = np.power(mat_db, 2)\n",
    "\n",
    "        num = np.sum(mat_diff)\n",
    "        den = np.sum(mat_sq)\n",
    "\n",
    "        scores.append(num/den)\n",
    "\n",
    "    return np.sum(scores)\n",
    "\n"
   ]
  },
  {
   "source": [
    "The output writers function just write out in four different files the data that gave us good scores. The order of data is fixed:\n",
    "- the score\n",
    "- the ratio of acceptance (i.e how many trials were accepted over the total)\n",
    "- the efficiency\n",
    "- $\\theta_i$, $k_i$, $m_i$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_writer(score_ref, ratio, i, temp, acceptance, score, perc, dih, const,mult):\n",
    "    \n",
    "    score_ref, ratio = writer(score, score_ref, i, perc, temp, acceptance, ratio, dih, const, mult)\n",
    "\n",
    "    return score_ref, ratio\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "def writer(score, score_ref, i, perc, temp, acceptance, ratio, dih, const, mult):\n",
    "\n",
    "    for amino in ratio.keys():\n",
    "        path = 'metropolis_run/score_%s.txt' % amino \n",
    "        \n",
    "        ref_score = score_ref[amino]\n",
    "        sco = score[amino]\n",
    "        \n",
    "        rat = np.int(ratio[amino])\n",
    "        if sco < ref_score:\n",
    "            rat = rat + 1\n",
    "            with open(path, 'a') as file:\n",
    "                print('%f %f %f %f %f %f %f %f %f %f %f %f %f %f %f' %(score[amino], rat/(i+1), perc[amino], dih[amino][0], dih[amino][1], dih[amino][2], dih[amino][3], const[amino][0], const[amino][1], const[amino][2], const[amino][3], mult[amino][0], mult[amino][1], mult[amino][2], mult[amino][3]), file=file)\n",
    "            score_ref[amino] = score[amino]\n",
    "            ratio[amino] = rat\n",
    "            \n",
    "        else:\n",
    "            if np.exp(-(score[amino] - score_ref[amino]) / temp[amino]) > acceptance[amino]:\n",
    "                rat = rat + 1\n",
    "                with open(path, 'a') as file:\n",
    "                    print('%f %f %f %f %f %f %f %f %f %f %f %f %f %f %f' %(score[amino], rat/(i+1), perc[amino], dih[amino][0], dih[amino][1], dih[amino][2], dih[amino][3], const[amino][0], const[amino][1], const[amino][2], const[amino][3], mult[amino][0], mult[amino][1], mult[amino][2], mult[amino][3]), file=file)\n",
    "                ratio[amino] = rat\n",
    "    return score_ref, ratio"
   ]
  },
  {
   "source": [
    "As input, two dictionaries are required:\n",
    "- a dictionary of matrices from the database\n",
    "- a dictionary of dataframes from the simulation ramachandran plot\n",
    " This means that we will create RV for all the quantities of interest.  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_db = {'ALL':make_matrix(make_database())}\n",
    "rama_dict = read_rama('input/rama_diff_2.xvg')"
   ]
  },
  {
   "source": [
    "We base this notebook on Metropolis algorithm.\n",
    "This means that we will create random variables for each quantity of interest. Then we will compute the potential terms and the relative reweighting of the histogram.\n",
    "\n",
    "To accept the new move, it has to satisfy some parameters:\n",
    "- it has to be efficient, $E\\leq E_{ref}$, where $E_{ref}$ is chosen in the main.\n",
    "- its score must be lower than the best available score $S \\leq S_{best}$.\n",
    "\n",
    "In case it is efficient but the score is not smaller, it can still be accepted. We can define a Monte Carlo temperature $\\tau_{mc}$ and generate a random acceptance $\\alpha$. Given the current score $S$ and the best score $S_{best}$ , if\n",
    "$$ \\exp\\left[-\\frac{S-S_{best}}{\\tau}\\right] \\geq \\alpha$$\n",
    "holds, then the move is accepted.\n",
    "\n",
    "If the score is accepted, it becomes the new reference.\n",
    "\n",
    "The number of moves is decided in the for cycle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mat_db, rama_dict):\n",
    "    \n",
    "    score_ref = {'ALL':17.228867}\n",
    "    ratio = {'ALL':0}\n",
    "    for key in ratio.keys():\n",
    "        ratio[key] = np.int(ratio[key])\n",
    "    mult = {'ALL':[6,2,2,1]}\n",
    "\n",
    "    #Monte Carlo temperature\n",
    "    temp = {'ALL':0.06}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    #mat_0 = separate(mat_db)\n",
    "    #mat_1 = separate(rama_dict)\n",
    "    #print(mat_1)\n",
    "\n",
    "    for i in range(25000):\n",
    "        #start_time = time.time()\n",
    "        \n",
    "        #print(mat_db.keys())\n",
    "        acceptance = {'ALL':random.random()}\n",
    "        \n",
    "        dih, const, mult = randomizer(mult)\n",
    "        \n",
    "        score, perc = metropolis(mat_db, rama_dict, dih, const, mult, beta=1/2.4943389)\n",
    "        \n",
    "        score_ref, ratio = all_writer(score_ref, ratio, i, temp, acceptance, score, perc, dih, const, mult)\n",
    "\n",
    "    print('Metropolis done in %s seconds!' %(time.time() - start_time))\n",
    "\n",
    "    return 'Done!'\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "def metropolis(mat_db, rama_dict, dih, const, mult, beta):\n",
    "    \n",
    "    \n",
    "    for amino in dih.keys():\n",
    "        rama_dict[amino] = make_weights(rama_dict[amino], dih[amino], const[amino], mult[amino], beta)\n",
    "        #print(type(rama_dict['GLY']))\n",
    "    \n",
    "    \n",
    "    perc = {'ALL':np.array(efficiency_analysis(rama_dict['ALL'])).mean()}\n",
    "    #print(perc)\n",
    "    score = {}\n",
    "\n",
    "    for amino in dih.keys():\n",
    "        if  np.float(perc[amino]) >= 0.65:\n",
    "            score[amino] = score_comp(mat_db[amino], rama_dict[amino])\n",
    "        else:\n",
    "            score[amino] = 1000\n",
    "\n",
    "    return score, perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metropolis done in 17775.53225684166 seconds!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Done!'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "main(mat_db, rama_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}